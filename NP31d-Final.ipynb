{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"g4cHz9c0MfIa"},"outputs":[],"source":["# Run in Colab GPU instance (e.g. T4) as it is needed to load models fitted with a GPU (NP bug?)\n","!pip uninstall -y torch notebook notebook_shim tensorflow tensorflow-datasets prophet torchaudio torchdata torchtext torchvision\n","!pip install git+https://github.com/ourownstory/neural_prophet.git"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SWlGBGIN0r1B"},"outputs":[],"source":["#To check status of GPUs\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awCYMb2tMqeN"},"outputs":[],"source":["import logging\n","import warnings\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import matplotlib as mpl\n","from matplotlib import gridspec\n","import pickle\n","import pandas as pd\n","import pickle\n","import os\n","import datetime\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from tqdm.auto import tqdm\n","\n","# from prophet import Prophet\n","from neuralprophet import NeuralProphet, set_log_level\n","\n","set_log_level(\"ERROR\")\n","logging.getLogger(\"prophet\").setLevel(logging.ERROR)\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","# MASE:  Mean Absolute Scaled Error compares the mean absolute error of the forecast with\n","# the mean absolute error of a naive forecast, i.e. the forecast that simply repeats the last observed value.\n","def mase(y_test,y_pred,y_train):\n","    return (y_test-y_pred.reset_index(drop=True)).abs().mean()/y_train.diff().dropna().abs().mean()\n"]},{"cell_type":"code","source":["# Connecting to Google Drive and mount project to running instance\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"RT3nX_MIfBvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9LkGj3ICM84q"},"outputs":[],"source":["# Need to manually set project path.\n","fpath='/content/drive/MyDrive/Colab Notebooks/Capstone'\n","\n","print(f\"Project filepath, fpath: {fpath}\")\n","\n","\n","# Load cleaned and reformated sales data\n","with open(fpath+'/data/df_v_m2.pkl', 'rb') as f:\n","    ddict=pickle.load(f)\n","    df_v_m=ddict['df_v_m']\n","    df_v_m_test=ddict['df_v_m_test']\n","# read price data\n","df_p_m=pd.read_pickle(fpath+'/data/df_flat_pvp.pkl')\n","df_p_m_test=pd.read_pickle(fpath+'/data/df_flat_pvp_test.pkl')\n","df_p_m_test[\"MED_GOA\"]=df_p_m_test.loc[:,[c for c in df_p_m_test.columns if 'GOA' in c]].median(axis=1)\n","df_p_m_test[\"MED_95\"]=df_p_m_test.loc[:,[c for c in df_p_m_test.columns if '95' in c]].median(axis=1)\n","\n","# nearest station info for each station (3&8 have same prices so use 2nd nearest for them)\n","stn_near=pd.read_pickle(fpath+'/data/stn_near.pkl')\n","\n","# read holidays defined in data and test period\n","df_hol_base=pd.read_pickle(fpath+'/data/df_hol_base.pkl')\n","\n","# add extra holidays/events to the base holidays\n","# Neuralprophet uses only 'event' not both 'holiday' and 'event' as prophet\n","# Defined as days that appear repeatedly in the time series as low sales days but are not official holidays\n","# are assumed to be foreseeable events that can be used to improve the forecast\n","with open(fpath+'/data/df_holi_extra.pkl', 'rb') as f:\n","    dict_hol_extra=pickle.load(f)\n","\n","\n","# dicts to store model performance statistics for later comparison\n","dict_MASE={}\n","dict_MAE={}\n","\n","# Model names\n","model_names={1:'Seasonal\\nNeuralProphet',2:'Seasonal+AR',3:'Seasonal\\n+AR-Net',4:'Seasonal\\n+AR-Net+Meteo',\n","             5:'Seasonal\\n+AR+$\\Delta$y',6:'Seasonal+AR+\\n$\\Delta$y+Meteo',\n","             7:'Seasonal+AR+\\n$\\Delta$y+Meteo\\n+$\\Delta$PVP',8:'Seasonal+AR+\\n$\\Delta$y+Meteo\\n+$\\Delta$PVP+nearby $\\Delta$PVP'}\n","\n","# Function to draw the resulting forecast compared to test data\n","def plt_mth(df_mth,stn,model):\n","\n","    fig,ax=plt.subplots(1,1,figsize=(12,8))\n","    ax.plot(df_mth.index,df_mth.y,label='Test',color='darkred',lw=2)\n","    ax.plot(df_mth.index,df_mth.yhatn,label='Forecast',color='darkblue',ls='--',lw=2)\n","    ax.fill_between(df_mth.index,df_mth['yhat lower'],df_mth['yhat upper'],color='lightblue',alpha=0.5)\n","    ax.grid('both')\n","    ax.legend()\n","    ax.set_ylabel('Sales')\n","    errorpct=(df_mth.yhatn.sum()-df_mth.y.sum())/df_mth.y.sum()\n","    ax.set_title(f\"Forecast for {stn} using model {model_names[model]} Error: {errorpct*100:.1f}%\")\n","    return fig,ax\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dNAIbeWPVPhD"},"source":["# 1. Seasonalities only"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S-PPvNGeVLig"},"outputs":[],"source":["import os\n","\n","dict_M = {}\n","valid = False\n","modelnr=1\n","fit_model=False # True to fit model, False to load fitted model from disk\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    # no extra holidays for ALL or 95 sales\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\": # seeing the effects of extra holidays if it improves the forecast and worth the effort\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        if df_hol_extra.loc[df_hol_extra.ds==datetime.datetime(2018,1,5)].shape[0]==1: #add extra event for 2019-01-04 if 2018-01-05 is present\n","            df_hol_extra=pd.concat([df_hol_extra,pd.DataFrame({'ds':[datetime.datetime(2019,1,4)],'event':['Ev01']},index=[0])],ignore_index=True)\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","    else:\n","        df_hol=df_hol_base\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","\n","    m=NeuralProphet(\n","                    yearly_seasonality=True,\n","                    weekly_seasonality=True,\n","                    daily_seasonality=False,\n","                    n_forecasts=31,\n","                    quantiles=[0.05,0.95],\n","                    epochs=60,\n","                    )\n","\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","\n","    if fit_model:\n","        if valid:\n","            df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","            metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","        else:\n","            df_train=df_new\n","            metrics=m.fit(df_train,freq='D', progress='bar')\n","        print(metrics.tail(1))\n","\n","        # save fitted model to disk\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","            pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","            m=pickle.load(f)\n","\n","\n","    # forecast_train = m.predict(df_new)\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol),events_df=df_hol,\n","                                  periods=31, n_historic_predictions=31*1)\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    else: # rolling the model forward 31 days on the first day\n","\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol),events_df=df_hol,\n","                                    periods=1, n_historic_predictions=31*1)\n","      forecast_test = m.predict(future)\n","\n","      f31d=forecast_test.loc[forecast_test.ds=='2018-12-31',[f\"yhat{i}\" for i in range(1,32)]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 95.0%' in c]].T\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    # fig,ax=plt.subplots(figsize=(10,6))\n","    # f31d.plot(ax=ax,grid=True,lw=2,title=f\"{stn} model {modelnr} sales 31d forecast vs. test data\",xlabel=\"Date\",ylabel=f\"{stn} sales\")\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","\n","    plt.close()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UAq2mMDaVPhG"},"source":["# 2. One month (31d) ahead forecast with Auto-Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bxN85lsqVPhG"},"outputs":[],"source":["valid=False\n","dict_M = {}\n","modelnr=2\n","fit_model=False\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    # no extra holidays for ALL or 95 sales\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\":\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        if df_hol_extra.loc[df_hol_extra.ds==datetime.datetime(2018,1,5)].shape[0]==1: #add extra event for 2019-01-04 if 2018-01-05 is present\n","            df_hol_extra=pd.concat([df_hol_extra,pd.DataFrame({'ds':[datetime.datetime(2019,1,4)],'event':['Ev01']},index=[0])],ignore_index=True)\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","    else:\n","        df_hol=df_hol_base\n","\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","\n","    m=NeuralProphet(\n","                yearly_seasonality=True,\n","                weekly_seasonality=True,\n","                daily_seasonality=False,\n","                seasonality_mode=\"additive\",\n","                n_lags=7,\n","                ar_reg=.1,\n","                n_forecasts=31,\n","                quantiles=[0.05,0.95],\n","                #epochs=60,\n","                )\n","\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","\n","    if fit_model:\n","        if valid:\n","            df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","            metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","        else:\n","            df_train=df_new\n","            metrics=m.fit(df_train,freq='D', progress='bar')\n","        print(metrics.tail(1))\n","\n","        # save fitted model to disk\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","            pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","            m=pickle.load(f)\n","\n","\n","\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol),events_df=df_hol,\n","                                  periods=31, n_historic_predictions=31*1)\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","    else: # rolling the model forward 31 days on the first day\n","\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol), events_df=df_hol,\n","                                periods=31, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future,raw=True)\n","      f31d=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and '%' not in c]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 95.0%' in c]].T\n","\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    # fig,ax=plt.subplots(figsize=(10,6))\n","    # f31d.plot(ax=ax,grid=True,lw=2,title=f\"{stn} model {modelnr} sales 31d forecast vs. test data\",xlabel=\"Date\",ylabel=f\"{stn} sales\")\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"mwfwnY3GVPhH"},"source":["# 3 One month (31d) ahead forecast modeling AR with a Neural Network (AR-Net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IuGJ34IoVPhH"},"outputs":[],"source":["valid=False\n","dict_M = {}\n","modelnr=3\n","fit_model=False\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\":\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","    else:\n","        df_hol=df_hol_base\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","    nl=8\n","    valid=False\n","\n","    m=NeuralProphet(\n","            yearly_seasonality=True,\n","            weekly_seasonality=True,\n","            daily_seasonality=False,\n","            seasonality_mode=\"additive\",\n","            n_lags=7,\n","            n_forecasts=31,\n","            quantiles=[0.05,0.95],\n","            ar_layers=[nl, nl, nl, nl],\n","            ar_reg=10,\n","            # learning_rate=0.003,\n","            )\n","\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","\n","    if fit_model:\n","        if valid:\n","            df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","            metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","        else:\n","            df_train=df_new\n","            metrics=m.fit(df_train,freq='D', progress='bar')\n","        print(metrics.tail(1))\n","\n","        # save fitted model to disk\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","            pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","            m=pickle.load(f)\n","\n","\n","\n","\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol),events_df=df_hol,\n","                                  periods=31, n_historic_predictions=31*1)\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    else: # rolling the model forward 31 days on the first day\n","\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol), events_df=df_hol,\n","                                periods=31, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future,raw=True)\n","      f31d=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and '%' not in c]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 95.0%' in c]].T\n","\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","\n","    plt.close()\n"]},{"cell_type":"markdown","metadata":{"id":"LqKa6dGQVPhH"},"source":["# 4 AR-Net + meteo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1Yf1VFTVPhI"},"outputs":[],"source":["dict_M={}\n","valid=False\n","modelnr=4\n","fit_model=False\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\":\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        if df_hol_extra.loc[df_hol_extra.ds==datetime.datetime(2018,1,5)].shape[0]==1: #add extra event for 2019-01-04 if 2018-01-05 is present\n","            df_hol_extra=pd.concat([df_hol_extra,pd.DataFrame({'ds':[datetime.datetime(2019,1,4)],'event':['Ev01']},index=[0])],ignore_index=True)\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","    else:\n","        df_hol=df_hol_base\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","    nl=8\n","    valid=False\n","\n","    # add weather data, temp, precipitation, wind\n","    df[\"tmed\"] = df_v_m.tmed.values\n","    df[\"prec\"] = df_v_m.prec.values\n","    df[\"velmedia\"] = df_v_m.velmedia.values\n","    df[\"sol\"] = df_v_m.sol.values\n","    df[\"racha\"] = df_v_m.racha.values\n","\n","    df_test[\"tmed\"] = df_v_m_test.tmed.values\n","    df_test[\"prec\"] = df_v_m_test.prec.values\n","    df_test[\"velmedia\"] = df_v_m_test.velmedia.values\n","    df_test[\"sol\"] = df_v_m_test.sol.values\n","    df_test[\"racha\"]= df_v_m_test.racha.values\n","\n","    m=NeuralProphet(\n","            yearly_seasonality=True,\n","            weekly_seasonality=True,\n","            daily_seasonality=False,\n","            seasonality_mode=\"additive\",\n","            n_lags=7,\n","            n_forecasts=31,\n","            quantiles=[0.05,0.95],\n","            ar_layers=[nl, nl, nl, nl],\n","            ar_reg=10,\n","            # learning_rate=0.003,\n","            )\n","\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    # add weather data as future regressors and assume reliable weather forecast is available for 1 day ahead\n","    m.add_future_regressor(\"tmed\",normalize=\"standardize\")\n","    m.add_future_regressor(\"prec\",normalize=\"standardize\")\n","    m.add_future_regressor(\"velmedia\",normalize=\"standardize\")\n","    m.add_future_regressor(\"sol\",normalize=\"standardize\")\n","    m.add_future_regressor(\"racha\",normalize=\"standardize\")\n","\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","    if fit_model:\n","        if valid:\n","            df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","            metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","        else:\n","            df_train=df_new\n","            metrics=m.fit(df_train,freq='D', progress='bar')\n","        print(metrics.tail(1))\n","\n","        # save fitted model to disk\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","            pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","            m=pickle.load(f)\n","\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","\n","    regressors_list=['tmed','prec','velmedia','sol','racha',]\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df,df_test]),df_hol),\n","                                    regressors_df=m.create_df_with_events(pd.concat([df,df_test]),df_hol).loc[:,regressors_list],\n","                                    periods=31, n_historic_predictions=31*1)\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","    else: # rolling the model forward 31 days on the first day\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol), events_df=df_hol,\n","                                regressors_df=pd.concat([df,df_test]).loc[:,regressors_list],\n","                                periods=31, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future,raw=True)\n","      f31d=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and '%' not in c]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 95.0%' in c]].T\n","\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"Z-kiO8EeVPhI"},"source":["# 5 One (1) step ahead forecast using Auto-Regression $+\\Delta y$ lagged regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvMQvw_lVPhI"},"outputs":[],"source":["valid=False\n","dict_M={}\n","modelnr=5\n","fit_model=False\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    # no extra holidays for ALL or 95 sales\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\":\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        if df_hol_extra.loc[df_hol_extra.ds==datetime.datetime(2018,1,5)].shape[0]==1: #add extra event for 2019-01-04 if 2018-01-05 is present\n","            df_hol_extra=pd.concat([df_hol_extra,pd.DataFrame({'ds':[datetime.datetime(2019,1,4)],'event':['Ev01']},index=[0])],ignore_index=True)\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","    else:\n","        df_hol=df_hol_base\n","\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","\n","    lagg_I=pd.concat([df,df_test],ignore_index=True).y.diff().fillna(0)\n","\n","    #df2=df.copy(deep=True)\n","    df[\"I\"] = lagg_I.iloc[:len(df)].values\n","\n","    #df_test2=df_test.copy(deep=True)\n","    df_test[\"I\"]=lagg_I.iloc[len(df):].values\n","\n","\n","    m=NeuralProphet(\n","                    yearly_seasonality=True,\n","                    weekly_seasonality=True,\n","                    daily_seasonality=False,\n","                    seasonality_mode=\"additive\",\n","                    n_lags=7,\n","                    ar_reg=1,\n","                    n_forecasts=31,\n","                    quantiles=[0.05,0.95],\n","                    #epochs=60,\n","                    )\n","\n","    m.add_lagged_regressor(\"I\",normalize=\"standardize\",n_lags=7)\n","\n","\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","\n","    if fit_model:\n","       if valid:\n","          df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","          metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","       else:\n","          df_train=df_new\n","          metrics=m.fit(df_train,freq='D', progress='bar')\n","       print(metrics.tail(1))\n","\n","      # save fitted model to disk\n","       with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","          pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","          m=pickle.load(f)\n","\n","\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      print(\"One forecast!\")\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df,df_test]),df_hol), events_df=df_hol,\n","                        regressors_df=pd.DataFrame({'ds':np.append(df_new.ds.values,df_test.ds.values),'I':lagg_I.values}).reset_index(drop=True),\n","                                     periods=31, n_historic_predictions=31*4)\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","    else: # rolling the model forward 31 days on the first day\n","\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol), events_df=df_hol,\n","                        regressors_df=pd.DataFrame({'ds':np.append(df_new.ds.values,df_test.ds.values),'I':lagg_I.values}).reset_index(drop=True),\n","                                periods=31, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future,raw=True)\n","      f31d=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and '%' not in c]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 95.0%' in c]].T\n","\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"P0XeeRZVVPhI"},"source":["# 6 One month (31d) step ahead forecast using AR, $+\\Delta y$ lagged regressor and meteo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzTXacGHVPhI"},"outputs":[],"source":["dict_M={}\n","valid=False\n","\n","modelnr=6\n","fit_model=False\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    # add extra holidays/events\n","    # with open(fpath+'/df_holi_extra.pkl', 'rb') as f:\n","    #     dict_hol_extra=pickle.load(f)\n","\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\":\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        df_hol_extra=pd.concat([df_hol_extra,pd.DataFrame({'ds':[datetime.datetime(2019,1,4)],'event':['Ev01']},index=[0])],ignore_index=True)\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","        print(df_hol_extra)\n","    else:\n","        df_hol=df_hol_base\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","    # add lagged regressor with difference of y\n","    # do the difference on concatenated df and df_test for continuity\n","    lagg_I=pd.concat([df,df_test],ignore_index=True).y.diff().fillna(0)\n","\n","    df[\"I\"] = lagg_I.iloc[:len(df)].values\n","    df_test[\"I\"]=lagg_I.iloc[len(df):].values\n","\n","    # add weather data, temp, precipitation, wind\n","    # df[\"tmax\"] = df_v_m.tmax.values\n","    df[\"tmed\"] = df_v_m.tmed.values\n","    # df[\"tmin\"] = df_v_m.tmin.values\n","    df[\"prec\"] = df_v_m.prec.values\n","    df[\"velmedia\"] = df_v_m.velmedia.values\n","    df[\"sol\"] = df_v_m.sol.values\n","    df[\"racha\"] = df_v_m.racha.values\n","\n","    # df_test[\"tmax\"] = df_v_m_test.tmax.values\n","    df_test[\"tmed\"] = df_v_m_test.tmax.values\n","    # df_test[\"tmin\"] = df_v_m_test.tmax.values\n","    df_test[\"prec\"] = df_v_m_test.prec.values\n","    df_test[\"velmedia\"] = df_v_m_test.velmedia.values\n","    df_test[\"sol\"] = df_v_m_test.sol.values\n","    df_test[\"racha\"] = df_v_m_test.racha.values\n","\n","    m=NeuralProphet(\n","                    yearly_seasonality=True,\n","                    weekly_seasonality=True,\n","                    daily_seasonality=False,\n","                    seasonality_mode=\"additive\",\n","                    n_lags=7,\n","                    ar_reg=0.1,\n","                    n_forecasts=31,\n","                    quantiles=[0.05,0.95],\n","                    #epochs=60,\n","                    )\n","\n","    # add holidays\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    # add lagged regressor\n","    m.add_lagged_regressor(\"I\",normalize=\"standardize\",n_lags=7,regularization=0.1)\n","\n","    # add weather data as future regressors and assume reliable weather forecast is available for 1 day ahead\n","    # m.add_future_regressor(\"tmax\",normalize=\"standardize\")\n","    m.add_future_regressor(\"tmed\",normalize=\"standardize\")\n","    # m.add_future_regressor(\"tmin\",normalize=\"standardize\")\n","    m.add_future_regressor(\"prec\",normalize=\"standardize\")\n","    m.add_future_regressor(\"velmedia\",normalize=\"standardize\")\n","    m.add_future_regressor(\"sol\",normalize=\"standardize\")\n","    m.add_future_regressor(\"racha\",normalize=\"standardize\")\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","\n","\n","    if fit_model:\n","        if valid:\n","            df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","            metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","        else:\n","            df_train=df_new\n","            metrics=m.fit(df_train,freq='D', progress='bar')\n","        print(metrics.tail(1))\n","\n","        # save fitted model to disk\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","            pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","            m=pickle.load(f)\n","\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","    # Forecast test period\n","    regressors_list=['I','tmed','prec','velmedia','sol','racha']\n","\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      print(\"One forecast!\")\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df,df_test]),df_hol), events_df=df_hol,\n","                                  regressors_df=pd.concat([df,df_test]).loc[:,regressors_list],\n","                                  periods=1, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","\n","    else: # rolling the model forward 31 days on the first day\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol), events_df=df_hol,\n","                                regressors_df=pd.concat([df]).loc[:,regressors_list],\n","                                periods=31, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future,raw=True)\n","      f31d=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and '%' not in c]].T\n","      # f31d=forecast_test.loc[forecast_test.ds=='2018-12-31',[f\"yhat{i}\" for i in range(1,32)]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 5.0%' in c]].T\n","      # f31_5=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 95.0%' in c]].T\n","      # f31_95=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 95.0%' in c]].T\n","\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"fPWOxBEhVPhJ"},"source":["## 7. Model 6 with added PVP deviation from median as lagged regressor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IkVmzoiZVPhJ"},"outputs":[],"source":["dict_M={}\n","valid=False\n","modelnr=7\n","fit_model=False\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    # add extra holidays/events\n","    # with open(fpath+'/df_holi_extra.pkl', 'rb') as f:\n","    #     dict_hol_extra=pickle.load(f)\n","\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\":\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        df_hol_extra=pd.concat([df_hol_extra,pd.DataFrame({'ds':[datetime.datetime(2019,1,4)],'event':['Ev01']},index=[0])],ignore_index=True)\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","        print(df_hol_extra)\n","    else:\n","        df_hol=df_hol_base\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","    # add lagged regressor with difference of y\n","    # do the difference on concatenated df and df_test for continuity\n","    lagg_I=pd.concat([df,df_test],ignore_index=True).y.diff().fillna(0)\n","\n","    df[\"I\"] = lagg_I.iloc[:len(df)].values\n","    df_test[\"I\"]=lagg_I.iloc[len(df):].values\n","\n","    # add weather data, temp, precipitation, wind\n","    # df[\"tmax\"] = df_v_m.tmax.values\n","    df[\"tmed\"] = df_v_m.tmed.values\n","    # df[\"tmin\"] = df_v_m.tmin.values\n","    df[\"prec\"] = df_v_m.prec.values\n","    df[\"velmedia\"] = df_v_m.velmedia.values\n","    df[\"sol\"] = df_v_m.sol.values\n","    df[\"racha\"] = df_v_m.racha.values\n","\n","    # add price deviation from median for this station\n","    df[\"pvpdev\"]=(df_p_m[stn]-df_p_m[\"MED_\"+stn.split('_')[1]]).values\n","\n","    # df_test[\"tmax\"] = df_v_m_test.tmax.values\n","    df_test[\"tmed\"] = df_v_m_test.tmax.values\n","    # df_test[\"tmin\"] = df_v_m_test.tmax.values\n","    df_test[\"prec\"] = df_v_m_test.prec.values\n","    df_test[\"velmedia\"] = df_v_m_test.velmedia.values\n","    df_test[\"sol\"] = df_v_m_test.sol.values\n","    df_test[\"racha\"] = df_v_m_test.racha.values\n","\n","    # add price deviation from median for this station\n","    df_test[\"pvpdev\"]=(df_p_m_test[stn]-df_p_m_test[\"MED_\"+stn.split('_')[1]]).values\n","\n","    m=NeuralProphet(\n","                    yearly_seasonality=True,\n","                    weekly_seasonality=True,\n","                    daily_seasonality=False,\n","                    seasonality_mode=\"additive\",\n","                    n_lags=7,\n","                    ar_reg=0.1,\n","                    n_forecasts=31,\n","                    quantiles=[0.05,0.95],\n","                    #epochs=60,\n","                    )\n","\n","    # add holidays\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    # add lagged regressor\n","    m.add_lagged_regressor(\"I\",normalize=\"standardize\",n_lags=7,regularization=0.1)\n","    m.add_lagged_regressor(\"pvpdev\",normalize=\"standardize\")\n","\n","    # add weather data as future regressors and assume reliable weather forecast is available for 1 day ahead\n","    # m.add_future_regressor(\"tmax\",normalize=\"standardize\")\n","    m.add_future_regressor(\"tmed\",normalize=\"standardize\")\n","    # m.add_future_regressor(\"tmin\",normalize=\"standardize\")\n","    m.add_future_regressor(\"prec\",normalize=\"standardize\")\n","    m.add_future_regressor(\"velmedia\",normalize=\"standardize\")\n","    m.add_future_regressor(\"sol\",normalize=\"standardize\")\n","    m.add_future_regressor(\"racha\",normalize=\"standardize\")\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","\n","\n","    if fit_model:\n","        if valid:\n","            df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","            metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","        else:\n","            df_train=df_new\n","            metrics=m.fit(df_train,freq='D', progress='bar')\n","        print(metrics.tail(1))\n","\n","        # save fitted model to disk\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","            pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","            m=pickle.load(f)\n","\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","    # Forecast test period\n","    regressors_list=['I','pvpdev','tmed','prec','velmedia','sol','racha']\n","\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      print(\"One forecast!\")\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df,df_test]),df_hol), events_df=df_hol,\n","                                  regressors_df=pd.concat([df,df_test]).loc[:,regressors_list],\n","                                  periods=1, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","\n","    else: # rolling the model forward 31 days on the first day\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol), events_df=df_hol,\n","                                regressors_df=pd.concat([df,df_test]).loc[:,regressors_list],\n","                                periods=31, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future,raw=True)\n","      f31d=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and '%' not in c]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 95.0%' in c]].T\n","\n","      # f31d=forecast_test.loc[forecast_test.ds=='2018-12-31',[f\"yhat{i}\" for i in range(1,32)]].T\n","      # f31_5=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 5.0%' in c]].T\n","      # f31_95=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 95.0%' in c]].T\n","\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","    plt.close()"]},{"cell_type":"markdown","metadata":{"id":"uCuZQncrVPhJ"},"source":["## 8. Model 7 with added PVP deviation of nearest station"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j5xy4SajVPhJ"},"outputs":[],"source":["dict_M={}\n","valid=False\n","modelnr=8\n","fit_model=False\n","\n","\n","fpathm = fpath+f\"/m31_{modelnr}\"\n","if not os.path.exists(fpathm):\n","    os.mkdir(fpathm)\n","\n","for stn in tqdm([f\"ES{nr}_{pr}\" for nr in range(1,13) for pr in [\"95\",\"GOA\"]]):\n","\n","    # add extra holidays/events\n","    # with open(fpath+'/df_holi_extra.pkl', 'rb') as f:\n","    #     dict_hol_extra=pickle.load(f)\n","\n","    if stn[:2]=='ES' and stn[-3:]==\"GOA\":\n","        df_hol_extra=dict_hol_extra[f\"df_holi_extra_{stn}\"]\n","        df_hol_extra=pd.concat([df_hol_extra,pd.DataFrame({'ds':[datetime.datetime(2019,1,4)],'event':['Ev01']},index=[0])],ignore_index=True)\n","        df_hol=pd.concat([df_hol_base,df_hol_extra],ignore_index=True)\n","        print(f\"Added {df_hol_extra.shape[0]} extra holidays for\",stn)\n","        print(df_hol_extra)\n","    else:\n","        df_hol=df_hol_base\n","\n","    df=df_v_m.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","    df_test=df_v_m_test.loc[:,[stn]].reset_index().rename(columns={'sale_date':'ds',stn:'y'})\n","\n","    # add lagged regressor with difference of y\n","    # do the difference on concatenated df and df_test for continuity\n","    lagg_I=pd.concat([df,df_test],ignore_index=True).y.diff().fillna(0)\n","\n","    df[\"I\"] = lagg_I.iloc[:len(df)].values\n","    df_test[\"I\"]=lagg_I.iloc[len(df):].values\n","\n","    # add weather data, temp, precipitation, wind\n","    # df[\"tmax\"] = df_v_m.tmax.values\n","    df[\"tmed\"] = df_v_m.tmed.values\n","    # df[\"tmin\"] = df_v_m.tmin.values\n","    df[\"prec\"] = df_v_m.prec.values\n","    df[\"velmedia\"] = df_v_m.velmedia.values\n","    df[\"sol\"] = df_v_m.sol.values\n","    df[\"racha\"] = df_v_m.racha.values\n","\n","    # add price deviation from median for this station\n","    df[\"pvpdev\"]=(df_p_m[stn]-df_p_m[\"MED_\"+stn.split('_')[1]]).values\n","    df[\"pvpdev_n\"]=(df_p_m[stn_near.loc[stn.split('_')[0]].Nearest+'_'+stn.split('_')[1]]\\\n","                  -df_p_m[\"MED_\"+stn.split('_')[1]]).values\n","    # df_test[\"tmax\"] = df_v_m_test.tmax.values\n","    df_test[\"tmed\"] = df_v_m_test.tmax.values\n","    # df_test[\"tmin\"] = df_v_m_test.tmax.values\n","    df_test[\"prec\"] = df_v_m_test.prec.values\n","    df_test[\"velmedia\"] = df_v_m_test.velmedia.values\n","    df_test[\"sol\"] = df_v_m_test.sol.values\n","    df_test[\"racha\"] = df_v_m_test.racha.values\n","\n","    # add price deviation from median for this station\n","    df_test[\"pvpdev\"]=(df_p_m_test[stn]-df_p_m_test[\"MED_\"+stn.split('_')[1]]).values\n","    df_test[\"pvpdev_n\"]=(df_p_m_test[stn_near.loc[stn.split('_')[0]].Nearest+'_'+stn.split('_')[1]]\\\n","                  -df_p_m_test[\"MED_\"+stn.split('_')[1]]).values\n","\n","    m=NeuralProphet(\n","                    yearly_seasonality=True,\n","                    weekly_seasonality=True,\n","                    daily_seasonality=False,\n","                    seasonality_mode=\"additive\",\n","                    n_lags=7,\n","                    ar_reg=0.1,\n","                    n_forecasts=31,\n","                    quantiles=[0.05,0.95],\n","                    #epochs=60,\n","                    )\n","\n","    # add holidays\n","    for e in df_hol.event.unique():\n","      m.add_events(e,regularization=None,mode='additive')#,lower_window=0,upper_window=1)\n","\n","    # add lagged regressor\n","    m.add_lagged_regressor(\"I\",normalize=\"standardize\",n_lags=7,regularization=0.1)\n","    m.add_lagged_regressor(\"pvpdev\",normalize=\"standardize\")\n","    m.add_lagged_regressor(\"pvpdev_n\",normalize=\"standardize\") #can add lags later\n","\n","    # add weather data as future regressors and assume reliable weather forecast is available for 1 day ahead\n","    # m.add_future_regressor(\"tmax\",normalize=\"standardize\")\n","    m.add_future_regressor(\"tmed\",normalize=\"standardize\")\n","    # m.add_future_regressor(\"tmin\",normalize=\"standardize\")\n","    m.add_future_regressor(\"prec\",normalize=\"standardize\")\n","    m.add_future_regressor(\"velmedia\",normalize=\"standardize\")\n","    m.add_future_regressor(\"sol\",normalize=\"standardize\")\n","    m.add_future_regressor(\"racha\",normalize=\"standardize\")\n","\n","    df_new=m.create_df_with_events(df, df_hol)\n","\n","\n","    if fit_model:\n","        if valid:\n","            df_train, df_val = m.split_df(df_new, freq=\"D\", valid_p=0.1)\n","            metrics=m.fit(df_train,freq='D',validation_df=df_val, progress='bar')\n","        else:\n","            df_train=df_new\n","            metrics=m.fit(df_train,freq='D', progress='bar')\n","        print(metrics.tail(1))\n","\n","        # save fitted model to disk\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"wb\") as f:\n","            pickle.dump(m, f, pickle.HIGHEST_PROTOCOL)\n","    else:\n","        print(\"Loading model from file: \"+fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl')\n","        with open(fpath+f'/models_31d/{stn}_model_{modelnr}_model.pkl', \"rb\") as f:\n","            m=pickle.load(f)\n","\n","\n","    m.set_plotting_backend(\"matplotlib\")\n","\n","    # Forecast test period\n","    regressors_list=['I','pvpdev','pvpdev_n','tmed','prec','velmedia','sol','racha']\n","\n","    # one forecast on '2018-12-31' for 31 days ahead (2019-01-01 to 2019-01-31)\n","    # in seasonal forecasting the model does not need own forecast to roll the model forward\n","    # so we can use the same model to forecast the next 31 days else we ask the model to roll the model forward 31 days\n","    if m.model.n_forecasts==1:\n","      print(\"One forecast!\")\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df,df_test]),df_hol), events_df=df_hol,\n","                                  regressors_df=pd.concat([df,df_test]).loc[:,regressors_list],\n","                                  periods=1, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future)\n","      f31d=forecast_test.loc[forecast_test.ds>'2018-12-31','ds':'trend']\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={'yhat1':'yhatn'},inplace=True)\n","\n","    else: # rolling the model forward 31 days on the first day\n","      future = m.make_future_dataframe(m.create_df_with_events(pd.concat([df]),df_hol), events_df=df_hol,\n","                                regressors_df=pd.concat([df,df_test]).loc[:,regressors_list],\n","                                periods=31, n_historic_predictions=31*1)\n","\n","      forecast_test = m.predict(future,raw=True)\n","      f31d=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and '%' not in c]].T\n","      f31_5=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 5.0%' in c]].T\n","      f31_95=forecast_test.loc[forecast_test.ds=='2019-01-01',[c for c in forecast_test.columns if 'step' in c and ' 95.0%' in c]].T\n","\n","      # f31d=forecast_test.loc[forecast_test.ds=='2018-12-31',[f\"yhat{i}\" for i in range(1,32)]].T\n","      # f31_5=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 5.0%' in c]].T\n","      # f31_95=forecast_test.loc[forecast_test.ds=='2018-12-31',[c for c in forecast_test.columns if ' 95.0%' in c]].T\n","\n","      f31d['yhat upper']=f31_95.values\n","      f31d['yhat lower']=f31_5.values\n","      f31d['ds']=df_test.ds.values\n","      f31d.set_index('ds',inplace=True)\n","      f31d.rename(columns={f31d.columns[0]:'yhatn'},inplace=True)\n","      f31d['y']=df_test.y.values\n","\n","    f31d.to_pickle(fpathm+f\"/{stn}_model_{modelnr}_f31d.pkl\")\n","\n","    # Plot 31d forecast vs. test data\n","    fig,ax=plt_mth(f31d.rename(columns={'yhat1 5.0%':'yhat lower','yhat1 95.0%':'yhat upper'}),stn,modelnr)\n","    fig.savefig(fpathm+f\"/{stn}_{modelnr}_31d_sales_forecast.png\",bbox_inches='tight')\n","\n","    print(f\"Model {modelnr}: {stn} 31d forecast {f31d.yhatn.sum():.2f} vs. test data {f31d.y.sum():.2f}.  Error: {-(f31d.y.sum()-f31d.yhatn.sum())/f31d.y.sum()*100:.1f}%\")\n","\n","    plt.close()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}